{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "soviet-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from import_data import import_training_data\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import xgboost\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score,KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "magnetic-volume",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: TrainingData",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-02ccdd4794d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# importing and splitting formatted data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finalLapTime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/LSTM-F1/models/import_data.py\u001b[0m in \u001b[0;36mimport_training_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM TrainingData'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: TrainingData"
     ]
    }
   ],
   "source": [
    "# importing and splitting formatted data\n",
    "\n",
    "df = import_training_data()\n",
    "label = df.pop('finalLapTime')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, label, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prepared-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tuning parameters\n",
    "parameters_for_testing = {\n",
    "   'colsample_bytree':[0.4,0.6,0.8],\n",
    "   'gamma':[0,0.03,0.1,0.3],\n",
    "   'min_child_weight':[1.5,6,10],\n",
    "   'learning_rate':[0.1,0.07],\n",
    "   'max_depth':[3,5],\n",
    "   'n_estimators':[500],\n",
    "   'subsample':[0.6,0.95]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-african",
   "metadata": {},
   "source": [
    "Now we want to run a grid search on the parameters defined above to find the optimal parameters for our XgBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "right-agriculture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed: 10.5min\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed: 17.1min\n",
      "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed: 20.5min\n",
      "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed: 25.2min\n",
      "[Parallel(n_jobs=6)]: Done 169 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=6)]: Done 209 tasks      | elapsed: 35.3min\n",
      "[Parallel(n_jobs=6)]: Done 230 tasks      | elapsed: 39.7min\n",
      "[Parallel(n_jobs=6)]: Done 253 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=6)]: Done 276 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=6)]: Done 301 tasks      | elapsed: 51.6min\n",
      "[Parallel(n_jobs=6)]: Done 326 tasks      | elapsed: 55.5min\n",
      "[Parallel(n_jobs=6)]: Done 353 tasks      | elapsed: 60.2min\n",
      "[Parallel(n_jobs=6)]: Done 380 tasks      | elapsed: 64.8min\n",
      "[Parallel(n_jobs=6)]: Done 409 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed: 74.2min\n",
      "[Parallel(n_jobs=6)]: Done 469 tasks      | elapsed: 79.9min\n",
      "[Parallel(n_jobs=6)]: Done 500 tasks      | elapsed: 84.8min\n",
      "[Parallel(n_jobs=6)]: Done 533 tasks      | elapsed: 90.4min\n",
      "[Parallel(n_jobs=6)]: Done 566 tasks      | elapsed: 96.1min\n",
      "[Parallel(n_jobs=6)]: Done 601 tasks      | elapsed: 102.2min\n",
      "[Parallel(n_jobs=6)]: Done 636 tasks      | elapsed: 107.8min\n",
      "[Parallel(n_jobs=6)]: Done 673 tasks      | elapsed: 114.2min\n",
      "[Parallel(n_jobs=6)]: Done 710 tasks      | elapsed: 121.2min\n",
      "[Parallel(n_jobs=6)]: Done 749 tasks      | elapsed: 127.0min\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed: 134.2min\n",
      "[Parallel(n_jobs=6)]: Done 829 tasks      | elapsed: 141.2min\n",
      "[Parallel(n_jobs=6)]: Done 870 tasks      | elapsed: 147.5min\n",
      "[Parallel(n_jobs=6)]: Done 913 tasks      | elapsed: 154.6min\n",
      "[Parallel(n_jobs=6)]: Done 956 tasks      | elapsed: 162.6min\n",
      "[Parallel(n_jobs=6)]: Done 1001 tasks      | elapsed: 169.6min\n",
      "[Parallel(n_jobs=6)]: Done 1046 tasks      | elapsed: 177.5min\n",
      "[Parallel(n_jobs=6)]: Done 1093 tasks      | elapsed: 185.7min\n",
      "[Parallel(n_jobs=6)]: Done 1140 tasks      | elapsed: 194.3min\n",
      "[Parallel(n_jobs=6)]: Done 1189 tasks      | elapsed: 202.9min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed: 211.3min\n",
      "[Parallel(n_jobs=6)]: Done 1289 tasks      | elapsed: 219.3min\n",
      "[Parallel(n_jobs=6)]: Done 1340 tasks      | elapsed: 228.6min\n",
      "[Parallel(n_jobs=6)]: Done 1393 tasks      | elapsed: 236.7min\n",
      "[Parallel(n_jobs=6)]: Done 1440 out of 1440 | elapsed: 245.0min finished\n",
      "/home/rufus/miniconda3/envs/tensorflow/lib/python3.8/site-packages/sklearn/model_selection/_search.py:847: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None, colsample_bytree=0.8,\n",
       "                                    gamma=0, gpu_id=None,\n",
       "                                    importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=0.1, max_delta_step=None,\n",
       "                                    max_depth=5, min_child_weight=1,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=1000, n_jobs=None, nthread=6,...\n",
       "                                    scale_pos_weight=1, seed=27, subsample=0.8,\n",
       "                                    tree_method='gpu_hist',\n",
       "                                    validate_parameters=None, verbosity=None),\n",
       "             iid=False, n_jobs=6,\n",
       "             param_grid={'colsample_bytree': [0.4, 0.6, 0.8],\n",
       "                         'gamma': [0, 0.03, 0.1, 0.3],\n",
       "                         'learning_rate': [0.1, 0.07], 'max_depth': [3, 5],\n",
       "                         'min_child_weight': [1.5, 6, 10],\n",
       "                         'n_estimators': [500], 'subsample': [0.6, 0.95]},\n",
       "             scoring='neg_mean_squared_error', verbose=10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb_model = xgboost.XGBRegressor(learning_rate =0.1, n_estimators=1000, max_depth=5,\n",
    "    min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,tree_method='gpu_hist', nthread=6, scale_pos_weight=1, seed=27)\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = xgb_model, param_grid = parameters_for_testing, n_jobs=6,iid=False, verbose=10,scoring='neg_mean_squared_error')\n",
    "gsearch1.fit(X_train,y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "mobile-scotland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'gamma': 0.03,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 1.5,\n",
       " 'n_estimators': 500,\n",
       " 'subsample': 0.95}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-receipt",
   "metadata": {},
   "source": [
    "# Best Model Parameters\n",
    "\n",
    "{'colsample_bytree': 0.8,\n",
    " 'gamma': 0.1,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 5,\n",
    " 'min_child_weight': 1.5,\n",
    " 'n_estimators': 500,\n",
    " 'subsample': 0.6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "together-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1612247 entries, 0 to 96921\n",
      "Data columns (total 48 columns):\n",
      " #   Column                     Non-Null Count    Dtype  \n",
      "---  ------                     --------------    -----  \n",
      " 0   lastLapTime                1612247 non-null  float64\n",
      " 1   currentLapTime             1612247 non-null  float64\n",
      " 2   currentLapNum              1612247 non-null  int64  \n",
      " 3   lapDistance                1612247 non-null  float64\n",
      " 4   carPosition                1612247 non-null  int64  \n",
      " 5   sector                     1612247 non-null  int64  \n",
      " 6   sessionUID                 1612247 non-null  object \n",
      " 7   worldPositionX             1612247 non-null  float64\n",
      " 8   worldPositionY             1612247 non-null  float64\n",
      " 9   worldPositionZ             1612247 non-null  float64\n",
      " 10  worldVelocityX             1612247 non-null  float64\n",
      " 11  worldVelocityY             1612247 non-null  float64\n",
      " 12  worldVelocityZ             1612247 non-null  float64\n",
      " 13  yaw                        1612247 non-null  float64\n",
      " 14  pitch                      1612247 non-null  float64\n",
      " 15  roll                       1612247 non-null  float64\n",
      " 16  speed                      1612247 non-null  int64  \n",
      " 17  throttle                   1612247 non-null  float64\n",
      " 18  steer                      1612247 non-null  float64\n",
      " 19  brake                      1612247 non-null  float64\n",
      " 20  clutch                     1612247 non-null  int64  \n",
      " 21  gear                       1612247 non-null  int64  \n",
      " 22  engineRPM                  1612247 non-null  int64  \n",
      " 23  drs                        1612247 non-null  int64  \n",
      " 24  brakesTemperatureRL        1612247 non-null  int64  \n",
      " 25  brakesTemperatureRR        1612247 non-null  int64  \n",
      " 26  brakesTemperatureFL        1612247 non-null  int64  \n",
      " 27  brakesTemperatureFR        1612247 non-null  int64  \n",
      " 28  tyresSurfaceTemperatureRL  1612247 non-null  int64  \n",
      " 29  tyresSurfaceTemperatureRR  1612247 non-null  int64  \n",
      " 30  tyresSurfaceTemperatureFL  1612247 non-null  int64  \n",
      " 31  tyresSurfaceTemperatureFR  1612247 non-null  int64  \n",
      " 32  engineTemperature          1612247 non-null  int64  \n",
      " 33  fuelMix                    1612247 non-null  int64  \n",
      " 34  FrontBrakeBias             1612247 non-null  int64  \n",
      " 35  fuelInTank                 1612247 non-null  float64\n",
      " 36  fuelRemainingLaps          1612247 non-null  float64\n",
      " 37  tyresWearRL                1612247 non-null  int64  \n",
      " 38  tyresWearRR                1612247 non-null  int64  \n",
      " 39  tyresWearFL                1612247 non-null  int64  \n",
      " 40  tyresWearFR                1612247 non-null  int64  \n",
      " 41  actualTyreCompound         1612247 non-null  int64  \n",
      " 42  tyresAgeLaps               1612247 non-null  int64  \n",
      " 43  frontLeftWingDamage        1612247 non-null  int64  \n",
      " 44  frontRightWingDamage       1612247 non-null  int64  \n",
      " 45  rearWingDamage             1612247 non-null  int64  \n",
      " 46  gearBoxDamage              1612247 non-null  int64  \n",
      " 47  engineDamage               1612247 non-null  int64  \n",
      "dtypes: float64(17), int64(30), object(1)\n",
      "memory usage: 602.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019292900640292765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df.info())\n",
    "\n",
    "df = df.drop(['sessionUID'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, label, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "tuned_model = xgboost.XGBRegressor(colsample_bytree = 0.8, gamma=0.03, learning_rate = 0.1, max_depth = 5,\n",
    "                                   min_child_weight = 1.5, n_estimators = 10000, subsample=0.95, \n",
    "                                   tree_method = 'gpu_hist')\n",
    "\n",
    "tuned_model.fit(X_train, y_train)\n",
    "pred = tuned_model.predict(X_test)\n",
    "err = mae(y_test, pred)\n",
    "display(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artistic-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = 'xgboost_model.pkl'\n",
    "pickle.dump(tuned_model, open(file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "structural-hobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.532291889190674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019292900640292765"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from time import time\n",
    "s = time()\n",
    "pred = tuned_model.predict(X_test)\n",
    "print(time()-s)\n",
    "err = mae(y_test, pred)\n",
    "display(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-treasurer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
