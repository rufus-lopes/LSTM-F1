{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices[0])\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-smoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_training_data():\n",
    "\n",
    "    ''' imports training data as a pandas DataFrame '''\n",
    "\n",
    "    dir = '../../SQL_Data/constant_setup'\n",
    "    files = os.listdir(dir)\n",
    "    files = [f for f in files if f.endswith('.sqlite3')]\n",
    "\n",
    "    data = []\n",
    "    for f in files:\n",
    "        path = os.path.join(dir, f)\n",
    "        conn = sqlite3.connect(path)\n",
    "        if os.path.getsize(path) > 10000:\n",
    "            cur = conn.cursor()\n",
    "            cur.execute('SELECT * FROM TrainingData')\n",
    "            df = pd.DataFrame(cur.fetchall())\n",
    "            data.append(df)\n",
    "\n",
    "    names = list(map(lambda x: x[0], cur.description))\n",
    "    df = pd.concat(data)\n",
    "    df.columns = names\n",
    "    df = df.drop(['frameIdentifier','bestLapTime', 'pkt_id', 'packetId', 'SessionTime', 'index' ], axis=1)\n",
    "    df.reset_index()\n",
    "\n",
    "    print('Data Imported')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(training, target):\n",
    "    \n",
    "    max_timesteps = 10000 # max(training, key=len).shape[0]\n",
    "    num_rows_to_add = [max_timesteps-l.shape[0] for l in training]\n",
    "    training_pad = []\n",
    "    target_pad = []\n",
    "    print(f'max timesteps : {max_timesteps}')\n",
    "    \n",
    "    for i in range(len(training)):\n",
    "        rows_to_add = num_rows_to_add[i]\n",
    "\n",
    "        training_arr = training[i]\n",
    "        training_append = np.zeros((rows_to_add, training[0].shape[1]), dtype=float)\n",
    "        training_array = np.vstack((training_arr, training_append))\n",
    "        training_pad.append(training_array)\n",
    "\n",
    "        target_arr = target[i].reshape(target[i].shape[0])\n",
    "        target_append = np.zeros((rows_to_add), dtype=float)\n",
    "        target_array = np.concatenate([target_arr, np.zeros(rows_to_add)])\n",
    "        target_pad.append(target_array)\n",
    "    \n",
    "    return training_pad, target_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    scalers = {}\n",
    "    sessionUIDs = data.pop('sessionUID')\n",
    "    lap_number = data.pop('currentLapNum')\n",
    "    for i in data.columns:\n",
    "        scaler = MinMaxScaler()\n",
    "        s = scaler.fit_transform(data[i].values.reshape(-1,1))\n",
    "        s = np.reshape(s, len(s))\n",
    "        scalers['scaler_'+ i ] = scaler\n",
    "        data[i] = s\n",
    "\n",
    "    data['sessionUID'] = sessionUIDs\n",
    "    data['currentLapNum'] = lap_number\n",
    "    \n",
    "    return data, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_format(data):\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    session_groups = data.groupby('sessionUID')\n",
    "    samples = []\n",
    "    targets = []\n",
    "    total_laps = 0\n",
    "    \n",
    "    for s in list(session_groups.groups):\n",
    "        session = session_groups.get_group(s)\n",
    "        lap_groups = session.groupby('currentLapNum')\n",
    "        total_laps += len(lap_groups)\n",
    "        for l in list(lap_groups.groups):\n",
    "            lap = lap_groups.get_group(l)\n",
    "            lap = lap.drop(['sessionUID'], axis=1)\n",
    "            targ = pd.DataFrame(lap.pop('lap_time_remaining'))\n",
    "            targets.append(targ)\n",
    "            samples.append(lap)\n",
    "    \n",
    "    sample_cols = list(samples[0].columns)\n",
    "    target_cols = list(targets[0].columns)\n",
    "\n",
    "    training = [x.to_numpy() for x in samples]\n",
    "    target = [y.to_numpy() for y in targets]\n",
    "    \n",
    "    training, target = pad_data(training, target)\n",
    "    \n",
    "    split = int(total_laps*0.9)\n",
    "\n",
    "    X_train = training[:split]\n",
    "    X_test  = training[split:]\n",
    "    y_train = target[:split]\n",
    "    y_test  = target[split:]\n",
    "    \n",
    "    \n",
    "    Xtrain = np.concatenate(X_train)\n",
    "    Xtest  = np.concatenate(X_test)\n",
    "    Ytrain = np.concatenate(y_train)\n",
    "    Ytest  = np.concatenate(y_test)\n",
    "    \n",
    "    trainX = pd.DataFrame(Xtrain, columns=sample_cols)\n",
    "    testX  = pd.DataFrame(Xtest, columns=sample_cols)\n",
    "    trainY = pd.DataFrame()\n",
    "    testY  = pd.DataFrame()\n",
    "    \n",
    "    trainY['lap_time_remaining'] = Ytrain\n",
    "    testY['lap_time_remaining']  = Ytest\n",
    "    \n",
    "    trainX.drop('currentLapNum', axis=1, inplace=True)\n",
    "    testX.drop('currentLapNum', axis=1, inplace=True)\n",
    "    \n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_generator(trainX, testX, trainY, testY):\n",
    "    ''' Creates train and test generators from data for a single lap/sequence'''\n",
    "\n",
    "    look_back = 5\n",
    "    batch_size = 1\n",
    "\n",
    "    train_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(trainX, trainY, length=look_back, sampling_rate=1, stride=1, batch_size=batch_size)\n",
    "    test_generator = tf.keras.preprocessing.sequence.TimeseriesGenerator(testX, testY, length=look_back, sampling_rate=1, stride=1, batch_size=1)\n",
    "\n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_generator):\n",
    "    ''' training the model'''\n",
    "    EPOCHS = 10\n",
    "    callback = [EarlyStopping(monitor=\"loss\", min_delta = 0.0001, patience = 10, mode = 'auto', \n",
    "                restore_best_weights=True),]\n",
    "                ModelCheckpoint('generator_lstm.h5')]\n",
    "    history = model.fit(train_generator, callbacks=callback, shuffle=False, epochs=EPOCHS, batch_size=1)\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-musical",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(train_generator):\n",
    "\n",
    "    ''' buils model and prints out summary'''\n",
    "    trainX, trainY = train_generator[0]\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    units = 128\n",
    "    epochs = 100\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, LSTM, Dropout, LeakyReLU\n",
    "    from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(trainX.shape[1], trainX.shape[2])))\n",
    "    model.add(LSTM(units, ))\n",
    "    model.add(LeakyReLU(alpha=0.5))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=adam, loss='mse', metrics=['mae'])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    print('Model Built')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = import_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('sample_data.csv')\n",
    "\n",
    "data, scalers = scale_data(data)\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = dataframe_format(data)\n",
    "\n",
    "trainX = train_X.to_numpy()\n",
    "testX  = test_X.to_numpy()\n",
    "trainY = train_Y.to_numpy()\n",
    "testY = test_Y.to_numpy()\n",
    "\n",
    "\n",
    "train_generator, test_generator = single_generator(trainX, testX, trainY, testY)\n",
    "\n",
    "model = build_model(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "history, model = train_model(model, train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, test_generator, scalers):\n",
    "    preds = scalers['scaler_lap_time_remaining'].inverse_transform(model.predict(test_generator))\n",
    "    return preds\n",
    " \n",
    "pred = make_predictions(model, test_generator, scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_Y['time_remaining_descaled'] = scalers['scaler_lap_time_remaining'].inverse_transform(test_Y['lap_time_remaining'].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pred.T\n",
    "predictions=[]\n",
    "\n",
    "for i in p:\n",
    "    preds = np.concatenate([i, np.zeros(5)]) \n",
    "\n",
    "    \n",
    "predictions=pd.Series(preds.ravel())\n",
    "\n",
    "test_Y['predictions'] = predictions\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap = 1\n",
    "labels = []\n",
    "for i in range(0, len(test_Y), 10000):\n",
    "    plt.plot(test_Y['predictions'])\n",
    "    labels.append(lap)\n",
    "    lap+=1\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-mention",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
